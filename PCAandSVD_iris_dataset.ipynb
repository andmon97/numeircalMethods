{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dimensionality Reduction and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example from sklearn documentation.\n",
    "Dimensionality reduction is the task of deriving a set of new\n",
    "artificial features that is smaller than the original feature\n",
    "set while retaining most of the variance of the original data.\n",
    "Here we'll use a common but powerful dimensionality reduction\n",
    "technique called Principal Component Analysis (PCA).\n",
    "We perform dimensionality reduction using first the singular value decomposition of the centered matrix and after the one computed by the PCA subroutine of sklearn.\n",
    "We work on the iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frances/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['f', 'e']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "%pylab inline\n",
    "# we plot the dataset composed on 3 column using a three dimensional space\n",
    "US = np.copy(X)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "target=iris.target\n",
    "#ax = fig.gca(projection='3d')\n",
    "fig = figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.plot(US[target==0,0],US[target==0,1],US[target==0,2],'bo')\n",
    "ax.plot(US[target==1,0],US[target==1,1],US[target==1,2],'ro')\n",
    "ax.plot(US[target==2,0],US[target==2,1],US[target==2,2],'go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is performed using linear combinations of the original features\n",
    "using a  Singular Value Decomposition of the matrix X so\n",
    "as to project the data onto a base of the top singular vectors.\n",
    "If the number of retained components is 2 or 3, PCA can be used\n",
    "to visualize the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "whiten=True\n",
    "ncomp=2\n",
    "pca = PCA(copy=True,n_components=ncomp,whiten=whiten).fit(X)\n",
    "# copy = True the matrix  X is not modified\n",
    "# n_components = number of computed singular values \n",
    "# withen = TRUE  the components are scaled to have unit variance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once fitted, the pca model exposes the singular vectors in the components_ attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direction of maximal variance are the vectors of the matrix V of the SVD\n",
    "# this are the rows of V^T\n",
    "pca.components_                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us project the iris dataset along those first two dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare this results with the singular value decomposition results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as la\n",
    "AS = np.copy(np.asarray(X))\n",
    "(nb, na) = AS.shape\n",
    "\n",
    "meanAS=np.mean(AS,axis=0).reshape(1,na)\n",
    "\n",
    "print('mean of the columns',meanAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the mean \n",
    "e = np.ones((nb,1))  \n",
    "AS = AS - np.dot(e,meanAS) # outer product using matrix operation\n",
    "print('mean of the columns after ', np.mean(AS,axis=0)) \n",
    "As1 = np.copy(np.asarray(X))\n",
    "As1 -=  meanAS # compacted outer product it is the same as using the outer product\n",
    "print('mean of the columns after ', np.mean(As1,axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the SVD\n",
    "U, s, Vh = la.svd(AS,full_matrices=False)\n",
    "\n",
    "US=np.copy(U)\n",
    "if whiten:\n",
    " US = US[:,0:ncomp]*s[0:ncomp]\n",
    " stdUS = np.std(US,axis=0,ddof=1) # the standard deviation is computed by dividing by sqrt(N-ddof)\n",
    " US = US/stdUS\n",
    "else:\n",
    " US = US[:,0:ncomp]*s[0:ncomp]\n",
    "\n",
    "print('Vh')\n",
    "print(Vh[0:2,:])\n",
    "\n",
    "print('pca_components')\n",
    "print(pca.components_)\n",
    "# to check the equality we compare the ratio element by element\n",
    "print('X_pca ratio  with  U_i*s_i')\n",
    "print(np.max(abs(X_pca/(US[:,0:ncomp]))),np.min(abs(X_pca/(US[:,0:ncomp]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using withen=True we have performed a standarditazion of the dataset, which means that the data are now centered  with unit variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_pca.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(X_pca.std(axis=0,ddof=1), decimals=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore the samples components do no longer carry any linear correlation, the correlation matrix is the identity matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.corrcoef(X_pca.T), decimals=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In thi example the covariance matrix is equal to the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.cov(X_pca.T), decimals=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The means of the columns is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X_pca,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round((X_pca.T.dot(X_pca))/(nb-1), decimals=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the results using the following utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def plot_PCA_1D(data, target, target_names):\n",
    "    colors = cycle('rgbcmykw')\n",
    "    target_ids = range(len(target_names))\n",
    "    figure()\n",
    "    for i, c, label in zip(target_ids, colors, target_names):\n",
    "          plot(data[target == i, 0],\n",
    "                   c=c, label=label,marker='o',linestyle = 'None')\n",
    "    legend()\n",
    "\n",
    "def plot_PCA_2D(data, target, target_names):\n",
    "    colors = cycle('rgbcmykw')\n",
    "    target_ids = range(len(target_names))\n",
    "    figure()\n",
    "    for i, c, label in zip(target_ids, colors, target_names):\n",
    "          scatter(data[target == i, 0], data[target == i, 1],\n",
    "                   c=c, label=label)\n",
    "    legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calling this function for our data, we see the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(X_pca[:,0],marker='o',linestyle = 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA_1D(X_pca, iris.target, iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this projection was determined *without* any information about the\n",
    "labels (represented by the colors): this is the sense in which the learning\n",
    "is unsupervised.  Nevertheless, we see that the projection gives us insight\n",
    "into the distribution of the different flowers in parameter space: notably,\n",
    "*iris setosa* is much more distinct than the other two species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA_2D(X_pca, iris.target, iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note also that the default implementation of PCA computes the SVD of the full\n",
    "data matrix, which is not scalable when both ``n_samples`` and\n",
    "``n_features`` are big (more that a few thousands).\n",
    "If you are interested in a number of components that is much\n",
    "smaller than both ``n_samples`` and ``n_features``, consider using\n",
    " special solvers for svd 'arpack' or 'randomized'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(copy=True,n_components=3, whiten=True,svd_solver='randomized').fit(X)\n",
    "US = pca.transform(X)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "target=iris.target\n",
    "fig = figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.plot(US[target==0,0],US[target==0,1],US[target==0,2],'ro')\n",
    "ax.plot(US[target==1,0],US[target==1,1],US[target==1,2],'go')\n",
    "ax.plot(US[target==2,0],US[target==2,1],US[target==2,2],'bo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA_1D(X_pca, iris.target, iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCA_2D(X_pca, iris.target, iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above dimensionality reduction with\n",
    "``Randomized`` or \"arpack\".\n",
    "\n",
    "You can re-use the ``plot_PCA_2D`` function from above.\n",
    "Are the results similar to those from standard PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "ns = 2\n",
    "t1=time.process_time()\n",
    "pca = PCA(copy=True,n_components=ns).fit(X)\n",
    "US = pca.transform(X)\n",
    "t2d=time.process_time()-t1\n",
    "print( \"clock  default = \", t2d )\n",
    "\n",
    "t1=time.process_time()\n",
    "pca = PCA(copy=True,n_components=ns,svd_solver='randomized').fit(X)\n",
    "US = pca.transform(X)\n",
    "t2d=time.process_time()-t1\n",
    "print( \"clock  randomized = \", t2d )\n",
    "\n",
    "\n",
    "t1=time.process_time()\n",
    "pca = PCA(copy=True,n_components=ns,svd_solver='arpack').fit(X)\n",
    "US = pca.transform(X)\n",
    "t2d=time.process_time()-t1\n",
    "print( \"clock  arpack= \", t2d )\n",
    "\n",
    "#apply arpack PCA to the iris data as above, and plot the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the projection on columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Asat=np.dot(U[:,0:4].T,AS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the observed values are reconstructed by adding the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xappr = np.dot(U[:,0:4],Asat) + np.dot(e,meanAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(Xappr-X,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simg = s\n",
    "f=simg**2. / np.sum(simg**2.)\n",
    "r = simg.shape\n",
    "entropy = (-1/np.log(r))*np.sum(f*np.log(f))\n",
    "ks = int(r*entropy)\n",
    "  #print('Entropy =',entropy, 'suggested k=', ks , simg[0:ks],)\n",
    "perc=(1-1e-4)\n",
    "nc = int(r*entropy*perc)+1   \n",
    "print('Entropy =',entropy, 'suggested k=', nc,r*entropy*perc,r,np.log(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
